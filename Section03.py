# -*- coding:utf-8 -*-
'''
ä½œè€…ï¼šcy
æ—¥æœŸï¼š2025å¹´11æœˆ06æ—¥
8.3 è¯­è¨€æ¨¡å‹å’Œæ•°æ®é›†

å‡è®¾é•¿åº¦ä¸ºTçš„æ–‡æœ¬åºåˆ—ä¸­çš„è¯å…ƒä¾æ¬¡ä¸ºx1, x2, . . . , xTã€‚äºæ˜¯ï¼Œxtï¼ˆ1 â‰¤ t â‰¤ Tï¼‰å¯ä»¥è¢«è®¤ä¸ºæ˜¯æ–‡
æœ¬åºåˆ—åœ¨æ—¶é—´æ­¥tå¤„çš„è§‚æµ‹æˆ–æ ‡ç­¾ã€‚åœ¨ç»™å®šè¿™æ ·çš„æ–‡æœ¬åºåˆ—æ—¶ï¼Œè¯­è¨€æ¨¡å‹ï¼ˆlanguage modelï¼‰çš„ç›®æ ‡æ˜¯ä¼°è®¡åº
åˆ—çš„è”åˆæ¦‚ç‡P(x1, x2, . . . , xT ).
'''

import Section02
import random
import torch
import matplotlib.pyplot as plt

# ä¸‹é¢çš„ä»£ç æ¯æ¬¡å¯ä»¥ä»æ•°æ®ä¸­éšæœºç”Ÿæˆä¸€ä¸ªå°æ‰¹é‡ã€‚
# åœ¨è¿™é‡Œï¼Œå‚æ•°batch_sizeæŒ‡å®šäº†æ¯ä¸ªå°æ‰¹é‡ä¸­å­åºåˆ—æ ·æœ¬çš„æ•°ç›®ï¼Œ
# å‚æ•°num_stepsæ˜¯æ¯ä¸ªå­åºåˆ—ä¸­é¢„å®šä¹‰çš„æ—¶é—´æ­¥æ•°ã€‚
# num_stepsï¼šæ¯ä¸ªè®­ç»ƒæ ·æœ¬ï¼ˆå­åºåˆ—ï¼‰åŒ…å«çš„è¯å…ƒæ•°é‡
# ä¹Ÿç§°ä¸ºï¼šåºåˆ—é•¿åº¦ã€æ—¶é—´æ­¥æ•°ã€ä¸Šä¸‹æ–‡é•¿åº¦
# num_steps å°±æ˜¯æ¯ä¸ªå­åºåˆ—çš„æœ€å¤§é•¿åº¦ï¼Œä¹Ÿå°±æ˜¯æ¨¡å‹åœ¨ä¸€æ¬¡å‰å‘ä¼ æ’­ä¸­å¤„ç†çš„è¯å…ƒåºåˆ—é•¿åº¦ã€‚
"""
å‡è®¾æ–‡æœ¬ï¼š"æ·±åº¦å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯"
åˆ†è¯åï¼š["æ·±åº¦", "å­¦ä¹ ", "æ˜¯", "äººå·¥", "æ™ºèƒ½", "çš„", "ä¸€ä¸ª", "é‡è¦", "åˆ†æ”¯"]ï¼Œ
é‚£ä¹ˆnum_steps =2å—ï¼Ÿå› ä¸ºåˆ†è¯ååºåˆ—é•¿åº¦æœ€å¤§æ˜¯2å•Šã€‚
ä¸å¯¹ã€‚
åˆ†è¯åçš„åºåˆ—é•¿åº¦ = æ•´ä¸ªæ–‡æœ¬åˆ†è¯åçš„è¯å…ƒæ€»æ•°ï¼Œä¸Šè¿°åˆ†è¯åæ˜¯9
è®¾ç½® num_steps = 4ï¼Œæ„æ€æ˜¯ï¼šæŠŠé•¿åº¦ä¸º9çš„é•¿åºåˆ—åˆ‡æˆå¤šä¸ªé•¿åº¦ä¸º4çš„å­åºåˆ—ã€‚

å¦‚æœ num_steps = 2ï¼šå¾—åˆ°4ä¸ªè®­ç»ƒæ ·æœ¬
å¦‚æœ num_steps = 4ï¼šå¾—åˆ°2ä¸ªè®­ç»ƒæ ·æœ¬
å¦‚æœ num_steps = 8ï¼šå¾—åˆ°1ä¸ªè®­ç»ƒæ ·æœ¬
å¦‚æœ num_steps = 9ï¼šå¾—åˆ°1ä¸ªè®­ç»ƒæ ·æœ¬ï¼ˆä½†ä¼šæµªè´¹ï¼Œå› ä¸ºéœ€è¦ç•™ä¸€ä¸ªä½ç½®ç»™æ ‡ç­¾ï¼‰
é€šå¸¸ num_steps ä¼šè®¾å¾—æ¯”æ–‡æœ¬é•¿åº¦å°ï¼Œè¿™æ ·æ‰èƒ½ä»å•ä¸ªæ–‡æœ¬ä¸­åˆ‡å‡ºå¤šä¸ªè®­ç»ƒæ ·æœ¬ã€‚
# å®é™…åº”ç”¨ä¸­æ ¹æ®æƒ…å†µé€‰æ‹©
num_steps = 32   # å°å‹æ¨¡å‹
num_steps = 512  # BERTç­‰æ¨¡å‹
num_steps = 2048 # GPTç³»åˆ—
ç ”ç©¶ä»»åŠ¡ï¼šéœ€è¦é•¿ä¸Šä¸‹æ–‡ç†è§£ï¼ˆå¦‚æ–‡æ¡£ç”Ÿæˆï¼‰â†’ é€‰è¾ƒå¤§çš„num_steps
è®¡ç®—èµ„æºï¼šèµ„æºæœ‰é™ â†’ é€‰è¾ƒå°çš„num_steps
æ•°æ®é‡ï¼šæ•°æ®å°‘ â†’ å¯ä»¥é€‰å¤§ä¸€äº›çš„num_steps
"""
"""
è®­ç»ƒé˜¶æ®µæœ€æ ¸å¿ƒçš„å…¬å¼
æ€»éœ€è¦Tokenæ•° = num_steps + 1
è¿™æ˜¯æ‰€æœ‰è®¡ç®—çš„åŸºçŸ³ï¼å› ä¸ºï¼š
è¾“å…¥éœ€è¦ï¼šnum_steps ä¸ªtoken
æ ‡ç­¾éœ€è¦ï¼šnum_steps ä¸ªtoken
ä½†å®ƒä»¬é‡å äº† num_steps - 1 ä¸ªtoken
æ‰€ä»¥å®é™…éœ€è¦ï¼šnum_steps + 1 ä¸ªåŸå§‹token

è®­ç»ƒé˜¶æ®µï¼ˆæœ‰è¿™ä¸ªå…¬å¼ï¼‰ï¼š
éœ€è¦ï¼šè¾“å…¥åºåˆ— + æ ‡ç­¾åºåˆ—
ç›®æ ‡ï¼šè®©æ¨¡å‹å­¦ä¹ "ç»™å®šå‰æ–‡é¢„æµ‹ä¸‹ä¸€ä¸ªè¯"
å¿…é¡»ï¼šæœ‰å®Œæ•´çš„è¾“å…¥-æ ‡ç­¾å¯¹
å…¬å¼ï¼šæ€»éœ€è¦Tokenæ•° = num_steps + 1
é¢„æµ‹é˜¶æ®µï¼ˆæ²¡æœ‰è¿™ä¸ªå…¬å¼ï¼‰ï¼š
åªéœ€è¦ï¼šè¾“å…¥åºåˆ—
ç›®æ ‡ï¼šç”Ÿæˆåç»­æ–‡æœ¬
å¯ä»¥ï¼šåªæœ‰è¾“å…¥ï¼Œæ²¡æœ‰æ ‡ç­¾
å…¬å¼ï¼šåªéœ€è¦ num_steps ä¸ªtokenå°±èƒ½å¼€å§‹é¢„æµ‹
"""
def seq_data_iter_random(corpus, batch_size, num_steps):
    """ä½¿ç”¨éšæœºæŠ½æ ·ç”Ÿæˆä¸€ä¸ªå°æ‰¹é‡å­åºåˆ—"""
    # ä»éšæœºåç§»é‡å¼€å§‹å¯¹åºåˆ—è¿›è¡Œåˆ†åŒºï¼ŒéšæœºèŒƒå›´åŒ…æ‹¬num_steps-1
    # å¦‚æœåç§»é‡æ˜¯ num_stepsï¼Œç›¸å½“äºä¸¢å¼ƒäº†æ•´æ•´ä¸€ä¸ªå­åºåˆ—çš„é•¿åº¦ï¼Œè¿™è¿‡äºæ¿€è¿›ã€‚
    # ä½†æ˜¯æ¯ä¸ªè®­ç»ƒæ ·æœ¬éœ€è¦ num_steps + 1 ä¸ªtokenï¼Œè€Œä¸æ˜¯ num_steps ä¸ª
    # ä¸ºäº†é¿å…æ— æ³•äº§ç”Ÿæ ‡ç­¾çš„å¯èƒ½æ€§
    corpus = corpus[random.randint(0, num_steps - 1):]
    # å‡å»1ï¼Œæ˜¯å› ä¸ºæˆ‘ä»¬éœ€è¦è€ƒè™‘æ ‡ç­¾
    # num_subseqsï¼šèƒ½åˆ‡å‡ºå¤šå°‘å®Œæ•´çš„å­åºåˆ—
    num_subseqs = (len(corpus) - 1) // num_steps
    # é•¿åº¦ä¸ºnum_stepsçš„å­åºåˆ—çš„èµ·å§‹ç´¢å¼•
    """
    range(start, stop, step) ä¸‰ä¸ªå‚æ•°ï¼š   
    startï¼šèµ·å§‹å€¼ï¼ˆåŒ…å«ï¼‰    
    stopï¼šç»“æŸå€¼ï¼ˆä¸åŒ…å«ï¼‰    
    stepï¼šæ­¥é•¿
    """
    initial_indices = list(range(0, num_subseqs * num_steps, num_steps))
    # åœ¨éšæœºæŠ½æ ·çš„è¿­ä»£è¿‡ç¨‹ä¸­æ¥è‡ªä¸¤ä¸ªç›¸é‚»çš„ã€éšæœºçš„ã€å°æ‰¹é‡ä¸­çš„å­åºåˆ—ä¸ä¸€å®šåœ¨åŸå§‹åºåˆ—ä¸Šç›¸é‚»
    random.shuffle(initial_indices)

    def data(pos):
        # è¿”å›ä»posä½ç½®å¼€å§‹çš„é•¿åº¦ä¸ºnum_stepsçš„åºåˆ—
        return corpus[pos: pos + num_steps]

    """
    num_subseqsï¼šæ€»å…±èƒ½åˆ‡å‡ºå¤šå°‘å®Œæ•´å­åºåˆ—
    batch_sizeï¼šæ¯ä¸ªæ‰¹é‡åŒ…å«å¤šå°‘ä¸ªå­åºåˆ—    
    num_batchesï¼šæ€»å…±å¤šå°‘æ‰¹é‡ = num_subseqs // batch_size   
    num_stepsï¼šæ¯ä¸ªå­åºåˆ—çš„é•¿åº¦
    ä¾‹å¦‚ï¼šnum_subseqs = 10    # æ€»å…±10ä¸ªå­åºåˆ—
    batch_size = 3      # æ¯æ‰¹3ä¸ªå­åºåˆ—
    num_steps = 5       # æ¯ä¸ªå­åºåˆ—é•¿åº¦5
    num_batches = 10 // 3 = 3  # å…±3ä¸ªå®Œæ•´æ‰¹é‡
    å‰©ä½™æ ·æœ¬æ•° = 10 % 3 = 1     # ç¬¬4ä¸ªæ‰¹é‡ä¸å®Œæ•´ï¼Œé€šå¸¸ä¸¢å¼ƒ
    ä¸€ä¸ªæ‰¹é‡åŒ…å«å¤šä¸ªå­åºåˆ—ã€‚
    """
    num_batches = num_subseqs // batch_size
    for i in range(0, batch_size * num_batches, batch_size):
        # åœ¨è¿™é‡Œï¼Œinitial_indicesåŒ…å«å­åºåˆ—çš„éšæœºèµ·å§‹ç´¢å¼•
        initial_indices_per_batch = initial_indices[i: i + batch_size]
        X = [data(j) for j in initial_indices_per_batch]
        Y = [data(j + 1) for j in initial_indices_per_batch]
        yield torch.tensor(X), torch.tensor(Y)

# åœ¨è¿­ä»£è¿‡ç¨‹ä¸­ï¼Œé™¤äº†å¯¹åŸå§‹åºåˆ—å¯ä»¥éšæœºæŠ½æ ·å¤–ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥ä¿è¯ä¸¤ä¸ªç›¸é‚»çš„å°æ‰¹é‡ä¸­çš„å­åºåˆ—åœ¨åŸå§‹åºåˆ—
# ä¸Šä¹Ÿæ˜¯ç›¸é‚»çš„ã€‚è¿™ç§ç­–ç•¥åœ¨åŸºäºå°æ‰¹é‡çš„è¿­ä»£è¿‡ç¨‹ä¸­ä¿ç•™äº†æ‹†åˆ†çš„å­åºåˆ—çš„é¡ºåºï¼Œå› æ­¤ç§°ä¸ºé¡ºåºåˆ†åŒºã€‚
"""
è¯å…ƒ (Token): è¿™æ˜¯æœ€åŸºæœ¬çš„å•ä½ã€‚æ‚¨å¯ä»¥å°†å…¶ç†è§£ä¸ºä¸€ä¸ªè¯ï¼ˆæˆ–ä¸€ä¸ªå­—ï¼Œæˆ–ä¸€ä¸ªæ ‡ç‚¹ç¬¦å·ï¼‰ã€‚
åœ¨ä»£ç ä¸­ï¼Œcorpus é‡Œçš„æ¯ä¸€ä¸ªæ•°å­—ï¼ˆå¦‚ corpus[i]ï¼‰å°±ä»£è¡¨ä¸€ä¸ªè¯å…ƒã€‚

åºåˆ— (Sequence): è¿™æ˜¯ç”±å¤šä¸ªè¯å…ƒç»„æˆçš„ã€‚ä»£ç ä¸­çš„ num_stepsï¼ˆæ—¶é—´æ­¥é•¿ï¼‰å®šä¹‰äº†æˆ‘ä»¬ä¸€æ¬¡å¤„ç†çš„åºåˆ—æœ‰å¤šé•¿ã€‚
ä¾‹å¦‚ï¼Œå¦‚æœ num_steps=35ï¼Œé‚£ä¹ˆä¸€ä¸ªåºåˆ—å°±æ˜¯ç”±35ä¸ªè¯å…ƒç»„æˆçš„ã€‚

æ‰¹æ¬¡ (Batch): è¿™æ˜¯ç”±å¤šä¸ªåºåˆ—ç»„æˆçš„ã€‚ä»£ç ä¸­çš„ batch_size å®šä¹‰äº†ä¸€ä¸ªæ‰¹æ¬¡é‡ŒåŒ…å«å¤šå°‘ä¸ªåºåˆ—ã€‚
"""
def seq_data_iter_sequential(corpus, batch_size, num_steps):
    """ä½¿ç”¨é¡ºåºåˆ†åŒºç”Ÿæˆä¸€ä¸ªå°æ‰¹é‡å­åºåˆ—"""
    # ä»éšæœºåç§»é‡å¼€å§‹åˆ’åˆ†åºåˆ—
    # random.randintç”Ÿæˆä¸€ä¸ªæŒ‡å®šèŒƒå›´å†…çš„éšæœºæ•´æ•°
    offset = random.randint(0, num_steps)
    num_tokens = ((len(corpus) - offset - 1) // batch_size) * batch_size
    Xs = torch.tensor(corpus[offset: offset + num_tokens])
    Ys = torch.tensor(corpus[offset + 1: offset + 1 + num_tokens])
    Xs, Ys = Xs.reshape(batch_size, -1), Ys.reshape(batch_size, -1)
    num_batches = Xs.shape[1] // num_steps
    for i in range(0, num_steps * num_batches, num_steps):
        X = Xs[:, i: i + num_steps]
        Y = Ys[:, i: i + num_steps]
        # äº§å‡ºï¼ˆâ€œè¿”å›â€ï¼‰å½“å‰çš„å°æ‰¹é‡ X å’Œ Yã€‚å‡½æ•°ä¼šåœ¨è¿™é‡Œæš‚åœï¼Œ
        # ç›´åˆ°ä¸‹ä¸€æ¬¡è¿­ä»£ï¼ˆä¾‹å¦‚ for å¾ªç¯ä¸­çš„ next()ï¼‰è¢«è°ƒç”¨ã€‚
        yield X, Y
# å°†ä¸Šé¢çš„ä¸¤ä¸ªé‡‡æ ·å‡½æ•°åŒ…è£…åˆ°ä¸€ä¸ªç±»ä¸­ï¼Œä»¥ä¾¿ç¨åå¯ä»¥å°†å…¶ç”¨ä½œæ•°æ®è¿­ä»£å™¨ã€‚
class SeqDataLoader:
    """åŠ è½½åºåˆ—æ•°æ®çš„è¿­ä»£å™¨"""
    def __init__(self, batch_size, num_steps, use_random_iter, max_tokens):
        if use_random_iter:
            self.data_iter_fn = seq_data_iter_random
        else:
            self.data_iter_fn = seq_data_iter_sequential
        self.corpus, self.vocab = Section02.load_corpus_time_machine(max_tokens)
        self.batch_size, self.num_steps = batch_size, num_steps

    def __iter__(self):
        return self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)


# å®šä¹‰ä¸€ä¸ªå‡½æ•°load_data_time_machineï¼Œå®ƒåŒæ—¶è¿”å›æ•°æ®è¿­ä»£å™¨å’Œè¯è¡¨
def load_data_time_machine(batch_size, num_steps, use_random_iter=False, max_tokens=10000):
    """è¿”å›æ—¶å…‰æœºå™¨æ•°æ®é›†çš„è¿­ä»£å™¨å’Œè¯è¡¨"""
    data_iter = SeqDataLoader(batch_size, num_steps, use_random_iter, max_tokens)
    return data_iter, data_iter.vocab

def main():
    """ä¸»å‡½æ•°ï¼ŒåŒ…å«æ‰€æœ‰éœ€è¦æ‰§è¡Œçš„ä»£ç """
    print("ğŸš€ Section03.py çš„ä¸»å‡½æ•°")
    # print(Section02.DATA_HUB)
    # print(Section02.DATA_URL)
    # æ ¹æ®8.2èŠ‚ä¸­ä»‹ç»çš„æ—¶å…‰æœºå™¨æ•°æ®é›†æ„å»ºè¯è¡¨ï¼Œå¹¶æ‰“å°å‰10ä¸ªæœ€å¸¸ç”¨çš„ï¼ˆé¢‘ç‡æœ€é«˜çš„ï¼‰å•è¯ã€‚
    # æ–‡æœ¬è½¬æ¢æˆè¯å…ƒ
    tokens = Section02.tokenize(Section02.read_time_machine())
    # å› ä¸ºæ¯ä¸ªæ–‡æœ¬è¡Œä¸ä¸€å®šæ˜¯ä¸€ä¸ªå¥å­æˆ–ä¸€ä¸ªæ®µè½ï¼Œå› æ­¤æˆ‘ä»¬æŠŠæ‰€æœ‰æ–‡æœ¬è¡Œæ‹¼æ¥åˆ°ä¸€èµ·
    """
    ä¸‹é¢ä¸€è¡Œæ›¿ä»£å½¢å¼ï¼š
    corpus = []
    for line in tokens:
        for token in line:
            corpus.append(token)
    """
    corpus = [token for line in tokens for token in line]
    # å°†è¯å…ƒè½¬æ¢æˆè¯æ±‡è¡¨å¯¹è±¡ï¼Œè¿™æ˜¯ä¸€ä¸ªç±»çš„å¯¹è±¡
    # æ„å»º token_to_idx å’Œ idx_to_token æ˜ å°„
    vocab = Section02.Vocab(corpus)
    print(vocab.token_freqs[:10])
    freqs = [freq for token, freq in vocab.token_freqs]
    """
    å›¾ä¸­æ˜¾ç¤ºï¼Œè¯é¢‘ä»¥ä¸€ç§æ˜ç¡®çš„æ–¹å¼è¿…é€Ÿè¡°å‡ã€‚è¿™æ„å‘³ç€å•è¯çš„é¢‘ç‡æ»¡è¶³é½æ™®å¤«å®šå¾‹ï¼ˆZipfâ€™s lawï¼‰ï¼Œlog ni = âˆ’Î± log i + c,
    è¿™å‘Šè¯‰æˆ‘ä»¬æƒ³è¦é€šè¿‡è®¡æ•°ç»Ÿè®¡å’Œå¹³æ»‘æ¥å»ºæ¨¡å•è¯æ˜¯ä¸å¯è¡Œçš„ï¼Œå› ä¸ºè¿™æ ·
    å»ºæ¨¡çš„ç»“æœä¼šå¤§å¤§é«˜ä¼°å°¾éƒ¨å•è¯çš„é¢‘ç‡ï¼Œä¹Ÿå°±æ˜¯æ‰€è°“çš„ä¸å¸¸ç”¨å•è¯ã€‚
    """
    # è®¾ç½®å›¾å½¢
    plt.figure(figsize=(6, 3))
    # ç»˜åˆ¶é¢‘ç‡åˆ†å¸ƒå›¾
    plt.plot(freqs)
    # è®¾ç½®åæ ‡è½´æ ‡ç­¾
    plt.xlabel('token: x')
    plt.ylabel('frequency: n(x)')
    # è®¾ç½®å¯¹æ•°åæ ‡è½´
    plt.xscale('log')
    plt.yscale('log')
    # æ·»åŠ ç½‘æ ¼å’Œæ ‡é¢˜
    plt.grid(True, alpha=0.3)
    plt.title('Token Frequency Distribution (Log-Log Scale)')
    plt.tight_layout()
    plt.show()
    # æŸ¥çœ‹äºŒå…ƒè¯­æ³•çš„é¢‘ç‡æ˜¯å¦ä¸ä¸€å…ƒè¯­æ³•çš„é¢‘ç‡è¡¨ç°å‡ºç›¸åŒçš„è¡Œä¸ºæ–¹å¼
    bigram_tokens = [pair for pair in zip(corpus[:-1], corpus[1:])]
    bigram_vocab = Section02.Vocab(bigram_tokens)
    print(bigram_vocab.token_freqs[:10])

    """
    corpus[:-2]ï¼šä»å¼€å§‹åˆ°å€’æ•°ç¬¬3ä¸ªå…ƒç´ 
    corpus[1:-1]ï¼šä»ç¬¬2ä¸ªåˆ°å€’æ•°ç¬¬2ä¸ªå…ƒç´    
    corpus[2:]ï¼šä»ç¬¬3ä¸ªåˆ°æœ€åä¸€ä¸ªå…ƒç´ 
    ä¸‹é¢ä¸€è¡Œåœ¨è¯å…ƒåŸºç¡€ä¸Šæ“ä½œï¼Œå®ç°çš„æ˜¯ï¼š
    # ä¸‰ä¸ªé”™ä½åˆ—è¡¨
    åˆ—è¡¨A: [1, 2, 3, 4]    â† corpus[:-2]
    åˆ—è¡¨B: [2, 3, 4, 5]    â† corpus[1:-1]  
    åˆ—è¡¨C: [3, 4, 5, 6]    â† corpus[2:]
    
    # zipå¹¶è¡Œå–å…ƒç´ 
    ç¬¬ä¸€æ¬¡å–ï¼šA[0]=1, B[0]=2, C[0]=3 â†’ triple=(1,2,3)
    ç¬¬äºŒæ¬¡å–ï¼šA[1]=2, B[1]=3, C[1]=4 â†’ triple=(2,3,4)
    ç¬¬ä¸‰æ¬¡å–ï¼šA[2]=3, B[2]=4, C[2]=5 â†’ triple=(3,4,5)
    ç¬¬å››æ¬¡å–ï¼šA[3]=4, B[3]=5, C[3]=6 â†’ triple=(4,5,6)
    ç»“æœï¼š[(1,2,3), (2,3,4), (3,4,5), (4,5,6)]
    æ¯ä¸ªtripleå°±æ˜¯è¿ç»­çš„ä¸‰ä¸ªè¯å…ƒã€‚
    """
    trigram_tokens = [triple for triple in zip(corpus[:-2], corpus[1:-1], corpus[2:])]
    """
    Vocab ä¸å…³å¿ƒè¯å…ƒç±»å‹ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ã€å•è¯æˆ–ä¸‰å…ƒç»„
    å®ƒæŠŠæ¯ä¸ªä¸‰å…ƒç»„ (1,2,3) å½“ä½œä¸€ä¸ªæ•´ä½“è¯å…ƒå¤„ç†
    ç»Ÿè®¡è¿™äº›ä¸‰å…ƒç»„çš„å‡ºç°é¢‘ç‡ï¼Œæ„å»º {ä¸‰å…ƒç»„: ç´¢å¼•} çš„æ˜ å°„
    ä¸‹é¢ä¸€è¡Œå¯èƒ½å®ç°çš„æ˜¯ï¼š
    token_to_idx = {(1,2,3): 0, (2,3,4): 1, ...}
    idx_to_token = [(1,2,3), (2,3,4), ...]
    """
    trigram_vocab = Section02.Vocab(trigram_tokens)
    print(trigram_vocab.token_freqs[:10])

    # ç›´è§‚åœ°å¯¹æ¯”ä¸‰ç§æ¨¡å‹ä¸­çš„è¯å…ƒé¢‘ç‡ï¼šä¸€å…ƒè¯­æ³•ã€äºŒå…ƒè¯­æ³•å’Œä¸‰å…ƒè¯­æ³•
    bigram_freqs = [freq for token, freq in bigram_vocab.token_freqs]
    trigram_freqs = [freq for token, freq in trigram_vocab.token_freqs]
    # è®¾ç½®å›¾å½¢
    plt.figure(figsize=(8, 5))
    # ç»˜åˆ¶å•å…ƒè¯­æ³•é¢‘ç‡
    plt.plot(freqs, label='unigram')
    # ç»˜åˆ¶äºŒå…ƒè¯­æ³•é¢‘ç‡
    plt.plot(bigram_freqs, label='bigram')
    # ç»˜åˆ¶ä¸‰å…ƒè¯­æ³•é¢‘ç‡
    plt.plot(trigram_freqs, label='trigram')
    # è®¾ç½®åæ ‡è½´æ ‡ç­¾å’Œæ¯”ä¾‹
    plt.xlabel('token: x')
    plt.ylabel('frequency: n(x)')
    plt.xscale('log')
    plt.yscale('log')
    # è®¾ç½®å›¾ä¾‹å’Œå…¶ä»–ç¾åŒ–
    plt.legend()
    plt.grid(True, alpha=0.3)
    # plt.title('N-gram Frequency Distribution')
    plt.tight_layout()
    plt.show()

    """
    token (è¯å…ƒ)ï¼šæ˜¯æ•°æ®çš„åŸºæœ¬å•ä½ï¼ˆæ¯”å¦‚ä¸€ä¸ªè¯æˆ–ä¸€ä¸ªå­—ï¼‰ã€‚
    num_stepsï¼šæ˜¯åºåˆ—çš„é•¿åº¦ï¼ˆlengthï¼‰ï¼Œè¿™ä¸ªé•¿åº¦çš„å•ä½å°±æ˜¯ tokenã€‚
    
    å‡è®¾è¯­æ–™åº“ corpus æ˜¯ä¸€å¥è¯ï¼š"The quick brown fox jumps over the lazy dog"ã€‚

    Tokenization (è¯å…ƒåŒ–): ä½ å…ˆæŠŠè¿™å¥è¯è½¬æ¢æˆ token åˆ—è¡¨ï¼š ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']
     ï¼ˆåœ¨ä»£ç ä¸­ï¼Œè¿™äº›è¯ä¼šè¢«è½¬æ¢æˆæ•°å­—IDï¼Œæ¯”å¦‚ [0, 1, 2, 3, 4, 5, 0, 6, 7]ï¼‰

    num_steps çš„ä½œç”¨:

    å¦‚æœè®¾ç½® num_steps = 3ï¼š é‚£ä¹ˆè¿™ä¸ªæ•°æ®è¿­ä»£å™¨å°±ä¼šæŠŠæ•°æ®åˆ‡æˆé•¿åº¦ä¸º 3 çš„åºåˆ—ã€‚æ¯”å¦‚ï¼Œäº§å‡ºçš„ä¸€ä¸ªå°æ‰¹é‡ X ä¸­çš„ä¸€ä¸ªåºåˆ—å¯èƒ½æ˜¯ï¼š
     ['The', 'quick', 'brown'] (å³ [0, 1, 2]) å¯¹åº”çš„ Y åºåˆ—å°±æ˜¯ï¼š ['quick', 'brown', 'fox'] (å³ [1, 2, 3])

    å¦‚æœè®¾ç½® num_steps = 5ï¼š é‚£ä¹ˆä¸€ä¸ªåºåˆ—å°±ä¼šæ˜¯ï¼š ['The', 'quick', 'brown', 'fox', 'jumps'] (å³ [0, 1, 2, 3, 4]) å¯¹åº”çš„ Y åºåˆ—å°±æ˜¯ï¼š
     ['quick', 'brown', 'fox', 'jumps', 'over'] (å³ [1, 2, 3, 4, 5])
    """
    # ä»æ•°æ®ä¸­éšæœºç”Ÿæˆä¸€ä¸ªå°æ‰¹é‡
    my_seq = list(range(35))
    for X, Y in seq_data_iter_random(my_seq, batch_size=2, num_steps=5):
        print('X: ', X, '\nY:', Y)

    # é€šè¿‡é¡ºåºåˆ†åŒºè¯»å–æ¯ä¸ªå°æ‰¹é‡çš„å­åºåˆ—çš„ç‰¹å¾Xå’Œæ ‡ç­¾Yã€‚
    for X, Y in seq_data_iter_sequential(my_seq, batch_size=2, num_steps=5):
        print('X: ', X, '\nY:', Y)

if __name__ == '__main__':
    main()
