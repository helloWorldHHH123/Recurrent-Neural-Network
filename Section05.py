# -*- coding:utf-8 -*-
'''
ä½œè€…ï¼šcy
æ—¥æœŸï¼š2025å¹´11æœˆ06æ—¥
8.5 å¾ªç¯ç¥ç»ç½‘ç»œçš„ä»é›¶å¼€å§‹å®ç°

æ— éšçŠ¶æ€çš„ç¥ç»ç½‘ç»œï¼šæ²¡æœ‰è®°å¿†ã€‚å®ƒå¤„ç†æ¯ä¸ªè¾“å…¥æ—¶ï¼Œéƒ½åƒæ˜¯ç¬¬ä¸€æ¬¡è§åˆ°ä¸€æ ·ï¼Œå®Œå…¨ç‹¬ç«‹ã€‚
æœ‰éšçŠ¶æ€çš„å¾ªç¯ç¥ç»ç½‘ç»œï¼šæ‹¥æœ‰è®°å¿†ã€‚å®ƒåœ¨å¤„ç†å½“å‰è¾“å…¥æ—¶ï¼Œä¼šå‚è€ƒå®ƒä¸Šä¸€æ­¥å¤„ç†è¿‡çš„è¾“å…¥ã€‚
'''

import math
import torch
from torch import nn
from torch.nn import functional as F
import Section02
import Section03
import numpy as np
import time


# 8.5.2 åˆå§‹åŒ–æ¨¡å‹å‚æ•°
# åˆå§‹åŒ–å¾ªç¯ç¥ç»ç½‘ç»œæ¨¡å‹çš„æ¨¡å‹å‚æ•°ã€‚éšè—å•å…ƒæ•°num_hiddensæ˜¯ä¸€ä¸ªå¯è°ƒçš„è¶…å‚æ•°ã€‚
# å½“è®­ç»ƒè¯­è¨€æ¨¡å‹æ—¶ï¼Œè¾“å…¥å’Œè¾“å‡ºæ¥è‡ªç›¸åŒçš„è¯è¡¨ã€‚å› æ­¤ï¼Œå®ƒä»¬å…·æœ‰ç›¸åŒçš„ç»´åº¦ï¼Œå³è¯è¡¨çš„å¤§å°ã€‚
def get_params(vocab_size, num_hiddens, device):
    num_inputs = num_outputs = vocab_size

    def normal(shape):
        return torch.randn(size=shape, device=device) * 0.01

    # éšè—å±‚å‚æ•°
    W_xh = normal((num_inputs, num_hiddens))
    W_hh = normal((num_hiddens, num_hiddens))
    b_h = torch.zeros(num_hiddens, device=device)
    # è¾“å‡ºå±‚å‚æ•°
    W_hq = normal((num_hiddens, num_outputs))
    b_q = torch.zeros(num_outputs, device=device)
    # é™„åŠ æ¢¯åº¦
    params = [W_xh, W_hh, b_h, W_hq, b_q]
    for param in params:
        param.requires_grad_(True)
    return params

# 8.5.3 å¾ªç¯ç¥ç»ç½‘ç»œæ¨¡å‹
def init_rnn_state(batch_size, num_hiddens, device):
    # ä¸ºä»€ä¹ˆæ˜¯0ï¼Ÿ è¿™æ˜¯ä¸€ç§æ ‡å‡†åšæ³•ï¼Œè¡¨ç¤ºåœ¨åºåˆ—å¼€å§‹æ—¶ï¼ŒRNNæ²¡æœ‰ä»»ä½•â€œå…ˆéªŒçŸ¥è¯†â€æˆ–â€œè®°å¿†â€ã€‚
    # è¿”å›çš„æ˜¯ä¸€ä¸ªåªåŒ…å«ä¸€ä¸ªå…ƒç´ çš„å…ƒç»„ï¼ˆTupleï¼‰
    """
    å¯¹äºç®€å•RNNï¼Œå®ƒè¿”å› (H_0,) â€”â€” ä¸€ä¸ªåŒ…å«åˆå§‹éšçŠ¶æ€çš„1å…ƒç»„ã€‚
    å¯¹äºLSTMï¼Œå®ƒä¼šè¿”å› (H_0, C_0) â€”â€” ä¸€ä¸ªåŒ…å«ä¸¤ä¸ªåˆå§‹çŠ¶æ€çš„2å…ƒç»„ã€‚
    è¿™æ ·åšçš„å¥½å¤„æ˜¯ï¼Œåç»­ä½¿ç”¨è¿™ä¸ªçŠ¶æ€çš„ rnn å‡½æ•°ä¸éœ€è¦æ”¹å˜ã€‚
    rnn å‡½æ•°å¯ä»¥ç»Ÿä¸€åœ°ä»å…ƒç»„ä¸­è§£åŒ…å®ƒéœ€è¦çš„çŠ¶æ€ï¼Œè€Œä¸ç”¨å»å…³å¿ƒå®ƒåˆ°åº•æ˜¯åœ¨å¤„ç†ç®€å•RNNè¿˜æ˜¯LSTMã€‚è¿™æ˜¯ä¸€ç§éå¸¸çµæ´»å’Œå¯æ‰©å±•çš„è®¾è®¡ã€‚
    """
    return (torch.zeros((batch_size, num_hiddens), device=device), )

# ä¸‹é¢çš„rnnå‡½æ•°å®šä¹‰äº†å¦‚ä½•åœ¨ä¸€ä¸ªæ—¶é—´æ­¥å†…è®¡ç®—éšçŠ¶æ€å’Œè¾“å‡ºã€‚
def rnn(inputs, state, params):
    # inputsçš„å½¢çŠ¶ï¼š(æ—¶é—´æ­¥æ•°é‡ï¼Œæ‰¹é‡å¤§å°ï¼Œè¯è¡¨å¤§å°)
    W_xh, W_hh, b_h, W_hq, b_q = params
    H, = state
    outputs = []
    # Xçš„å½¢çŠ¶ï¼š(æ‰¹é‡å¤§å°ï¼Œè¯è¡¨å¤§å°)
    for X in inputs:
        # H å°±æ˜¯â€œéšçŠ¶æ€â€ (Hidden State)ï¼Œå®ƒæ˜¯RNNçš„â€œè®°å¿†â€æ ¸å¿ƒã€‚
        # ä¸ºäº†è®©ç¥ç»ç½‘ç»œèƒ½å¤Ÿæœ‰æ•ˆåœ°â€œèåˆæ–°ä¿¡æ¯â€å’Œâ€œæ—§è®°å¿†â€ã€‚
        # RNNçš„ç›®æ ‡æ˜¯åœ¨æ¯ä¸ªæ—¶é—´æ­¥ tï¼Œæ ¹æ®å½“å‰è¾“å…¥ X_t å’Œä¸Šä¸€æ­¥çš„è®°å¿† H_{t-1}ï¼Œæ¥åˆ›é€ ä¸€ä¸ªæ–°çš„è®°å¿† H_tã€‚
        # ä¸‹é¢è¿™ä¸ªå…¬å¼åšçš„å°±æ˜¯è¿™ä¸ªï¼š
        H = torch.tanh(torch.mm(X, W_xh) + torch.mm(H, W_hh) + b_h)
        Y = torch.mm(H, W_hq) + b_q
        outputs.append(Y)
    return torch.cat(outputs, dim=0), (H,)

# å®šä¹‰äº†æ‰€æœ‰éœ€è¦çš„å‡½æ•°ä¹‹åï¼Œæ¥ä¸‹æ¥åˆ›å»ºä¸€ä¸ªç±»æ¥åŒ…è£…è¿™äº›å‡½æ•°ï¼Œ
# å¹¶å­˜å‚¨ä»é›¶å¼€å§‹å®ç°çš„å¾ªç¯ç¥ç»ç½‘ç»œæ¨¡å‹çš„å‚æ•°ã€‚
class RNNModelScratch:
    """ä»é›¶å¼€å§‹å®ç°çš„å¾ªç¯ç¥ç»ç½‘ç»œæ¨¡å‹"""
    def __init__(self, vocab_size, num_hiddens, device,get_params, init_state, forward_fn):
        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens
        self.params = get_params(vocab_size, num_hiddens, device)
        self.init_state, self.forward_fn = init_state, forward_fn

    def __call__(self, X, state):
        X = F.one_hot(X.T, self.vocab_size).type(torch.float32)
        # è°ƒç”¨rnn(inputs, state, params)
        return self.forward_fn(X, state, self.params)

    def begin_state(self, batch_size, device):
        # è°ƒç”¨init_rnn_state(batch_size, num_hiddens, device)
        return self.init_state(batch_size, self.num_hiddens, device)

def try_gpu(i=0):
    if torch.cuda.device_count()>=i+1:
        # PyTorch çš„è®¾å¤‡å­—ç¬¦ä¸²æœ‰ä¸¥æ ¼çš„æ ¼å¼è¦æ±‚ï¼š
        # f'cuda:{i}'ï¼Œå†’å·åé¢æ²¡æœ‰ç©ºæ ¼ï¼Œæ­£ç¡®
        # f'cuda: {i}'ï¼Œå†’å·åé¢æ²¡æœ‰ç©ºæ ¼ï¼Œé”™è¯¯
        return torch.device(f'cuda:{i}')
    return torch.device('cpu')

# 8.5.4 é¢„æµ‹
# é¦–å…ˆå®šä¹‰é¢„æµ‹å‡½æ•°æ¥ç”Ÿæˆprefixä¹‹åçš„æ–°å­—ç¬¦ï¼Œå…¶ä¸­çš„prefixæ˜¯ä¸€ä¸ªç”¨æˆ·æä¾›çš„åŒ…å«å¤šä¸ªå­—ç¬¦çš„å­—ç¬¦ä¸²ã€‚
# åœ¨å¾ªç¯éå†prefixä¸­çš„å¼€å§‹å­—ç¬¦æ—¶ï¼Œæˆ‘ä»¬ä¸æ–­åœ°å°†éšçŠ¶æ€ä¼ é€’åˆ°ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥ï¼Œä½†æ˜¯ä¸ç”Ÿæˆä»»ä½•è¾“å‡ºã€‚
# è¿™è¢«ç§°ä¸ºé¢„çƒ­ï¼ˆwarmâ€upï¼‰æœŸï¼Œå› ä¸ºåœ¨æ­¤æœŸé—´æ¨¡å‹ä¼šè‡ªæˆ‘æ›´æ–°ï¼ˆä¾‹å¦‚ï¼Œæ›´æ–°éšçŠ¶æ€ï¼‰ï¼Œä½†ä¸ä¼šè¿›è¡Œé¢„æµ‹ã€‚
# é¢„çƒ­æœŸç»“æŸåï¼ŒéšçŠ¶æ€çš„å€¼é€šå¸¸æ¯”åˆšå¼€å§‹çš„åˆå§‹å€¼æ›´é€‚åˆé¢„æµ‹ï¼Œä»è€Œé¢„æµ‹å­—ç¬¦å¹¶è¾“å‡ºå®ƒä»¬ã€‚
def predict_ch8(prefix, num_preds, net, vocab, device):
    """åœ¨prefixåé¢ç”Ÿæˆæ–°å­—ç¬¦"""
    state = net.begin_state(batch_size=1, device=device)
    outputs = [vocab[prefix[0]]]
    # è·å–outputsåˆ—è¡¨ä¸­çš„æœ€åä¸€ä¸ªå­—ç¬¦ç´¢å¼•ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸º (1, 1) å½¢çŠ¶çš„å¼ é‡ï¼ˆå³ batch_size=1, num_steps=1ï¼‰
    get_input = lambda: torch.tensor([outputs[-1]], device=device).reshape((1, 1))
    for y in prefix[1:]: # é¢„çƒ­æœŸ
        _, state = net(get_input(), state)
        outputs.append(vocab[y])
    for _ in range(num_preds): # é¢„æµ‹num_predsæ­¥
        y, state = net(get_input(), state)
        # y.argmax(...) æ‰¾å‡ºæ¦‚ç‡æœ€é«˜çš„é‚£ä¸ªå­—ç¬¦çš„ç´¢å¼•ï¼ˆå³æ¨¡å‹è®¤ä¸ºâ€œæœ€å¯èƒ½â€çš„ä¸‹ä¸€ä¸ªå­—ç¬¦ï¼‰ã€‚
        # å°†è¿™ä¸ªé¢„æµ‹å‡ºçš„æ–°å­—ç¬¦ç´¢å¼•æ·»åŠ åˆ° outputs åˆ—è¡¨ã€‚
        # è¿™ä¸ªæ–°æ·»åŠ çš„å­—ç¬¦å°†æˆä¸ºä¸‹ä¸€æ¬¡å¾ªç¯ä¸­ get_input() çš„æ¥æºã€‚è¿™ä¸ªè¿‡ç¨‹ï¼ˆç”¨è‡ªå·±çš„è¾“å‡ºä½œä¸ºä¸‹ä¸€æ­¥çš„è¾“å…¥ï¼‰è¢«ç§°ä¸ºè‡ªå›å½’ (Autoregressive)ã€‚
        outputs.append(int(y.argmax(dim=1).reshape(1)))
    # outputs åˆ—è¡¨ä¸­ç°åœ¨åŒ…å«äº†prefixçš„å…¨éƒ¨ç´¢å¼•å’Œæ‰€æœ‰num_predsä¸ªæ–°é¢„æµ‹çš„ç´¢å¼•ã€‚
    return ''.join([vocab.idx_to_token[i] for i in outputs])

# 8.5.5 æ¢¯åº¦è£å‰ª
# å¯¹äºé•¿åº¦ä¸ºTçš„åºåˆ—ï¼Œæˆ‘ä»¬åœ¨è¿­ä»£ä¸­è®¡ç®—è¿™Tä¸ªæ—¶é—´æ­¥ä¸Šçš„æ¢¯åº¦ï¼Œå°†ä¼šåœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­äº§ç”Ÿé•¿åº¦ä¸ºO(T)çš„
# çŸ©é˜µä¹˜æ³•é“¾ã€‚å¦‚ 4.8èŠ‚æ‰€è¿°ï¼Œå½“Tè¾ƒå¤§æ—¶ï¼Œå®ƒå¯èƒ½å¯¼è‡´æ•°å€¼ä¸ç¨³å®šï¼Œä¾‹å¦‚å¯èƒ½å¯¼è‡´æ¢¯åº¦çˆ†ç‚¸æˆ–æ¢¯åº¦æ¶ˆå¤±ã€‚
# å› æ­¤ï¼Œå¾ªç¯ç¥ç»ç½‘ç»œæ¨¡å‹å¾€å¾€éœ€è¦é¢å¤–çš„æ–¹å¼æ¥æ”¯æŒç¨³å®šè®­ç»ƒã€‚
def grad_clipping(net, theta):
    """è£å‰ªæ¢¯åº¦"""
    if isinstance(net, nn.Module):
        params = [p for p in net.parameters() if p.requires_grad]
    else:
        params = net.params
    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))
    if norm > theta:
        for param in params:
            param.grad[:] *= theta / norm

class Timer:
    def __init__(self):
        self.times = []
        self.start()
    def start(self):
        """å¯åŠ¨è®¡æ—¶å™¨"""
        self.tik = time.time()
    def stop(self):
        """åœæ­¢è®¡æ—¶å™¨å¹¶å°†æ—¶é—´è®°å½•åœ¨åˆ—è¡¨ä¸­"""
        self.times.append(time.time()-self.tik)
        return self.times[-1]
    def sum(self):
        """è¿”å›æ—¶é—´æ€»å’Œ"""
        return sum(self.times)
    def cumsum(self):
        """è¿”å›ç´¯è®¡æ—¶é—´"""
        """
        np.array(self.times) - å°†åˆ—è¡¨è½¬æ¢ä¸ºNumPyæ•°ç»„
        .cumsum() - è®¡ç®—ç´¯ç§¯å’Œ
        .tolist() - è½¬æ¢å›Pythonåˆ—è¡¨
        """
        return np.array(self.times).cumsum().tolist()

# 8.5.6 è®­ç»ƒ
def train_epoch_ch8(net, train_iter, loss, updater, device, use_random_iter):
    """è®­ç»ƒç½‘ç»œä¸€ä¸ªè¿­ä»£å‘¨æœŸï¼ˆå®šä¹‰è§ç¬¬8ç« ï¼‰"""
    state, timer = None, Timer()
    # è®­ç»ƒæŸå¤±ä¹‹å’Œ,è¯å…ƒæ•°é‡
    metric = [0.0] * 2
    for X, Y in train_iter:
        if state is None or use_random_iter:
            # åœ¨ç¬¬ä¸€æ¬¡è¿­ä»£æˆ–ä½¿ç”¨éšæœºæŠ½æ ·æ—¶åˆå§‹åŒ–state
            state = net.begin_state(batch_size=X.shape[0], device=device)
        else:
            # è¿™ä¸ª if æ¡ä»¶åªåœ¨ net æ˜¯ä¸€ä¸ªPyTorchå®˜æ–¹æ¨¡å—ï¼Œå¹¶ä¸”å®ƒè¿”å›çš„ state æ˜¯ä¸€ä¸ªå•ç‹¬çš„å¼ é‡ï¼ˆè€Œä¸æ˜¯å…ƒç»„ï¼‰æ—¶ï¼Œæ‰ä¼šä¸º Trueã€‚
            if isinstance(net, nn.Module) and not isinstance(state, tuple):
                # stateå¯¹äºnn.GRUæ˜¯ä¸ªå¼ é‡
                # .detach_() æ˜¯å®ç°â€œæˆªæ–­åå‘ä¼ æ’­â€ (Truncated BPTT) çš„å…³é”®ã€‚
                state.detach_()
            else:
                # stateå¯¹äºnn.LSTMæˆ–å¯¹äºæˆ‘ä»¬ä»é›¶å¼€å§‹å®ç°çš„æ¨¡å‹æ˜¯ä¸ªå¼ é‡
                for s in state:
                    s.detach_()
        # .reshape(-1) (å±•å¹³)
        y = Y.T.reshape(-1)
        X, y = X.to(device), y.to(device)
        # ä½ çš„ state å˜é‡å°±åƒä¸€ä¸ªå•ç‹¬çš„â€œè®°å¿†æ’æ§½â€ï¼Œå®ƒåªæŒæœ‰æœ€è¿‘ä¸€æ¬¡çš„éšçŠ¶æ€ã€‚
        y_hat, state = net(X, state)
        # y.long() çš„æ„æ€æ˜¯ï¼šå°† y è¿™ä¸ªå¼ é‡ï¼ˆTensorï¼‰çš„æ•°æ®ç±»å‹è½¬æ¢ä¸º torch.longï¼ˆå³64ä½æ•´å‹ï¼‰ã€‚
        l = loss(y_hat, y.long()).mean()
        if isinstance(updater, torch.optim.Optimizer):
            updater.zero_grad()
            l.backward()   # è®¡ç®—æ¢¯åº¦
            grad_clipping(net, 1)   # å¯¹å‚æ•°çš„â€œæ¢¯åº¦â€ (Gradients) è¿›è¡Œæˆªæ–­
            updater.step()   # ä½¿ç”¨è¿™ä¸¤æ ·ä¸œè¥¿ï¼šè£å‰ªåçš„æ¢¯åº¦ (Clipped Gradients)ï¼Œä¸Šä¸€æ­¥çš„å‚æ•°å€¼ (Old Parameter Values)æ¥æ‰§è¡Œä¸€æ¬¡å‚æ•°æ›´æ–°
        else:
            l.backward()
            grad_clipping(net, 1)
            # å› ä¸ºå·²ç»è°ƒç”¨äº†meanå‡½æ•°
            updater(batch_size=1)

        metric=[a+float(b) for a,b in zip(metric,[l * y.numel(), y.numel()])]
    return math.exp(metric[0] / metric[1]), metric[1] / timer.stop()

def sgd(params, lr, batch_size):
    """å°æ‰¹é‡éšæœºæ¢¯åº¦ä¸‹é™"""
    with torch.no_grad():
        for param in params:
            param -= lr * param.grad / batch_size
            param.grad.zero_()

# å¾ªç¯ç¥ç»ç½‘ç»œæ¨¡å‹çš„è®­ç»ƒå‡½æ•°æ—¢æ”¯æŒä»é›¶å¼€å§‹å®ç°ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨é«˜çº§APIæ¥å®ç°ã€‚
def train_ch8(net, train_iter, vocab, lr, num_epochs, device, use_random_iter=False):
    """è®­ç»ƒæ¨¡å‹ï¼ˆå®šä¹‰è§ç¬¬8ç« ï¼‰"""
    loss = nn.CrossEntropyLoss()
    # animator = d2l.Animator(xlabel='epoch', ylabel='perplexity',
    # legend=['train'], xlim=[10, num_epochs])
    # åˆå§‹åŒ–
    if isinstance(net, nn.Module):
        updater = torch.optim.SGD(net.parameters(), lr)
    else:
        updater = lambda batch_size: sgd(net.params, lr, batch_size)
    predict = lambda prefix: predict_ch8(prefix, 50, net, vocab, device)
    # è®­ç»ƒå’Œé¢„æµ‹
    for epoch in range(num_epochs):
        ppl, speed = train_epoch_ch8(net, train_iter, loss, updater, device, use_random_iter)
        if (epoch + 1) % 10 == 0:
            print(predict('time traveller'))
            # animator.add(epoch + 1, [ppl])
    print(f'å›°æƒ‘åº¦ {ppl:.1f}, {speed:.1f} è¯å…ƒ/ç§’ {str(device)}')
    print(predict('time traveller'))
    print(predict('traveller'))

def main():
    """ä¸»å‡½æ•°ï¼ŒåŒ…å«æ‰€æœ‰éœ€è¦æ‰§è¡Œçš„ä»£ç """
    print("ğŸš€ Section05.py çš„ä¸»å‡½æ•°")
    # num_stepsåŒ…å«å¤šä¸ªè¯å…ƒï¼ˆtokenï¼‰
    batch_size, num_steps = 32, 35
    # è¯æ±‡è¡¨å¯¹è±¡vocabï¼Œè¿™æ˜¯ä¸€ä¸ªç±»çš„å¯¹è±¡
    # æ„å»º token_to_idx å’Œ idx_to_token æ˜ å°„
    train_iter, vocab = Section03.load_data_time_machine(batch_size, num_steps)

    # 8.5.1 ç‹¬çƒ­ç¼–ç 
    print('ç‹¬çƒ­ç¼–ç : ', F.one_hot(torch.tensor([0, 2]), len(vocab)))
    X = torch.arange(10).reshape((2, 5))
    """
    .T æ˜¯è½¬ç½® (Transpose) æ“ä½œï¼Œå®ƒä¼šæŠŠ X çš„ç»´åº¦ï¼ˆè¡Œå’Œåˆ—ï¼‰äº¤æ¢ã€‚
    éå† X.T (å½¢çŠ¶ [5, 2]) ä¸­çš„æ¯ä¸€ä¸ªæ•´æ•°ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºä¸€ä¸ªé•¿åº¦ä¸º 28 çš„å‘é‡ã€‚
    ä¾‹å¦‚ï¼Œ0 ä¼šå˜æˆ [1, 0, 0, ..., 0] (é•¿åº¦28)
    ä¾‹å¦‚ï¼Œ5 ä¼šå˜æˆ [0, 0, 0, 0, 0, 1, ..., 0] (é•¿åº¦28)
    """
    print(F.one_hot(X.T, 28).shape)
    # 8.5.2 åˆå§‹åŒ–æ¨¡å‹å‚æ•°

    # æ£€æŸ¥è¾“å‡ºæ˜¯å¦å…·æœ‰æ­£ç¡®çš„å½¢çŠ¶ã€‚ä¾‹å¦‚ï¼ŒéšçŠ¶æ€çš„ç»´æ•°æ˜¯å¦ä¿æŒä¸å˜ã€‚
    num_hiddens = 512
    """
    æ²¡æœ‰åœ¨åˆ›å»º net æ—¶ è°ƒç”¨ get_paramsã€‚åªæ˜¯æŠŠ get_params è¿™ä¸ªå‡½æ•°æœ¬èº«ï¼ˆåƒä¸€ä¸ªâ€œè¯´æ˜ä¹¦â€æˆ–â€œé…æ–¹â€ï¼‰ä½œä¸ºå‚æ•°ä¼ é€’ç»™äº† RNNModelScratch çš„æ„é€ å‡½æ•° (__init__)ã€‚
    RNNModelScratch çš„æ„é€ å‡½æ•°å†…éƒ¨ä¼šæ¥æ”¶è¿™ä¸ªâ€œé…æ–¹â€ï¼Œç„¶åç”±å®ƒè‡ªå·±æ¥è°ƒç”¨è¿™ä¸ªå‡½æ•°ã€‚
    
    å½“åˆ›å»º net æ—¶ï¼ŒRNNModelScratch ç±»çš„ __init__ æ–¹æ³•ï¼ˆæ„é€ å‡½æ•°ï¼‰è¢«è°ƒç”¨ã€‚
    RNNModelScratch çš„ __init__ æ–¹æ³•åœ¨æ‰§è¡Œåˆ°å†…éƒ¨çš„ self.params = ... è¿™ä¸€è¡Œæ—¶ï¼Œ
    å®ƒä½¿ç”¨å®ƒå·²ç»æ‹¥æœ‰çš„ self.vocab_sizeã€self.num_hiddens å’Œ self.device ä½œä¸ºå‚æ•°ï¼Œ
    æ¥è°ƒç”¨å®ƒåˆšåˆšæ¥æ”¶åˆ°çš„ get_params_functionï¼ˆä¹Ÿå°±æ˜¯ä¼ è¿›å»çš„ get_paramsï¼‰
    
    è¿™ç§â€œå°†å‡½æ•°ä½œä¸ºå‚æ•°ä¼ é€’ï¼Œä»¥ä¾¿ç¨ååœ¨å†…éƒ¨è°ƒç”¨â€çš„æ¨¡å¼éå¸¸å¸¸è§ï¼Œå®ƒæ˜¯ä¸€ç§è§£è€¦ï¼ˆDecouplingï¼‰çš„è®¾è®¡ï¼š
    RNNModelScratch ç±»ä¸éœ€è¦çŸ¥é“å‚æ•°æ˜¯å¦‚ä½•è¢«åˆ›å»ºçš„ï¼ˆæ˜¯ç”¨ normal è¿˜æ˜¯ zeros è¿˜æ˜¯å…¶ä»–æ–¹æ³•ï¼‰ï¼Œ
    å®ƒåªå…³å¿ƒä¸€ä»¶äº‹ï¼šâ€œè¯·ç»™æˆ‘ä¸€ä¸ªå‡½æ•°ï¼Œè¿™ä¸ªå‡½æ•°èƒ½æ¥æ”¶ (vocab_size, hiddens, device) å¹¶è¿”å›æˆ‘éœ€è¦çš„ params åˆ—è¡¨å°±è¡Œâ€ã€‚
    """
    net = RNNModelScratch(len(vocab), num_hiddens, try_gpu(), get_params, init_rnn_state, rnn)
    state = net.begin_state(X.shape[0], try_gpu())
    Y, new_state = net(X.to(try_gpu()), state)
    print(Y.shape, len(new_state), new_state[0].shape)

    # æµ‹è¯•predict_ch8å‡½æ•°ã€‚æˆ‘ä»¬å°†å‰ç¼€æŒ‡å®šä¸ºtime travellerï¼Œå¹¶åŸºäºè¿™ä¸ªå‰ç¼€ç”Ÿæˆ10ä¸ªåç»­å­—ç¬¦ã€‚
    # é‰´äºæˆ‘ä»¬è¿˜æ²¡æœ‰è®­ç»ƒç½‘ç»œï¼Œå®ƒä¼šç”Ÿæˆè’è°¬çš„é¢„æµ‹ç»“æœã€‚
    """
    â€œé¢„çƒ­â€ï¼ˆWarm-upï¼‰æ˜¯å¦‚ä½•ä½¿ç”¨RNNï¼ˆå¾ªç¯ç¥ç»ç½‘ç»œï¼‰æ¥ç”Ÿæˆæ–‡æœ¬è¿™ä¸ªè¿‡ç¨‹ä¸­éå¸¸å…³é”®çš„ä¸€æ­¥ï¼Œå®ƒçš„æ„æ€æ˜¯ï¼š
    åœ¨è®©æ¨¡å‹â€œé¢„æµ‹â€æ–°å­—ç¬¦ä¹‹å‰ï¼Œå…ˆå¼ºè¿«å®ƒâ€œé˜…è¯»å¹¶ç†è§£â€ä½ ç»™å®ƒçš„ä¸Šä¸‹æ–‡ï¼ˆprefixï¼‰ã€‚
    æƒ³è±¡ä¸€ä¸‹RNNæ˜¯ä¸€ä¸ªäººï¼Œå®ƒçš„**â€œéšçŠ¶æ€â€ (Hidden State)** å°±æ˜¯å®ƒçš„**â€œçŸ­æœŸè®°å¿†â€**ã€‚
    åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬åªå…³å¿ƒæ›´æ–°å®ƒçš„â€œè®°å¿†â€ï¼ˆéšçŠ¶æ€ï¼‰ï¼Œè€Œä¸åœ¨ä¹å®ƒåœ¨é˜…è¯»æ¯ä¸ªå­—æ—¶â€œæƒ³â€äº†ä»€ä¹ˆï¼ˆå³ï¼Œæˆ‘ä»¬ä¸¢å¼ƒå®ƒåœ¨é¢„çƒ­æœŸé—´çš„æ‰€æœ‰è¾“å‡ºï¼‰ã€‚
    ä¸ºäº†è®©RNNç”Ÿæˆåˆç†è¿è´¯çš„æ–‡æœ¬ï¼Œä½ ä¸èƒ½è®©å®ƒâ€œå‡­ç©ºæƒ³è±¡â€ã€‚
    â€œé¢„çƒ­â€åœ¨å¹²ä»€ä¹ˆï¼šå®ƒé€šè¿‡å¤„ç† prefix å­—ç¬¦ä¸²ï¼Œå°†RNNçš„**éšçŠ¶æ€ï¼ˆè®°å¿†ï¼‰ä»ä¸€ä¸ªâ€œæ— ä¿¡æ¯â€çš„åˆå§‹çŠ¶æ€ï¼Œè½¬å˜ä¸ºä¸€ä¸ªâ€œå……æ»¡ä¸Šä¸‹æ–‡â€**çš„å°±ç»ªçŠ¶æ€ã€‚
    ä¸ºä»€ä¹ˆè¿™ä¹ˆåšï¼šåªæœ‰å½“RNNçš„â€œè®°å¿†â€é‡Œæœ‰äº† prefix çš„ä¸Šä¸‹æ–‡æ—¶ï¼Œå®ƒæ¥ä¸‹æ¥çš„é¢„æµ‹ï¼ˆç”Ÿæˆçš„æ–°å­—ç¬¦ï¼‰æ‰èƒ½ä¸ prefix é€»è¾‘ä¸Šè¡”æ¥èµ·æ¥ã€‚
    """
    # å‚æ•°ï¼šå­—ç¬¦ä¸²ï¼Œé¢„æµ‹æ­¥ï¼Œç½‘ç»œï¼Œè¯è¡¨ï¼Œè®¾å¤‡
    print(predict_ch8('time traveller ', 10, net, vocab, try_gpu()))

    # è®­ç»ƒå¾ªç¯ç¥ç»ç½‘ç»œæ¨¡å‹ã€‚å› ä¸ºæˆ‘ä»¬åœ¨æ•°æ®é›†ä¸­åªä½¿ç”¨äº†10000ä¸ªè¯å…ƒï¼Œ
    # æ‰€ä»¥æ¨¡å‹éœ€è¦æ›´å¤šçš„è¿­ä»£å‘¨æœŸæ¥æ›´å¥½åœ°æ”¶æ•›ã€‚
    num_epochs, lr = 500, 1
    train_ch8(net, train_iter, vocab, lr, num_epochs, try_gpu())

    # æ£€æŸ¥ä¸€ä¸‹ä½¿ç”¨éšæœºæŠ½æ ·æ–¹æ³•çš„ç»“æœã€‚
    net = RNNModelScratch(len(vocab), num_hiddens, try_gpu(), get_params, init_rnn_state, rnn)
    train_ch8(net, train_iter, vocab, lr, num_epochs, try_gpu(), use_random_iter=True)

if __name__ == '__main__':
    main()
